apiVersion: v1
kind: ConfigMap
metadata:
  name: go-carbon-config
data:
  go-carbon.conf: |
    [common]
    # Run as user. Works only in daemon mode
    user = "carbon"
    # Prefix for store all internal go-carbon graphs. Supported macroses: {host}
    graph-prefix = "carbon"
    # Endpoint for store internal carbon metrics. Valid values: "" or "local", "tcp://host:port", "udp://host:port"
    metric-endpoint = "local"
    # Interval of storing internal metrics. Like CARBON_METRIC_INTERVAL
    metric-interval = "1m0s"
    # Increase for configuration with multi persister workers
    max-cpu = 16

    [whisper]
    data-dir = "/data"
    # http://graphite.readthedocs.org/en/latest/config-carbon.html#storage-schemas-conf. Required
    schemas-file = "/etc/go-carbon/storage-schemas.conf"
    # http://graphite.readthedocs.org/en/latest/config-carbon.html#storage-aggregation-conf. Optional
    aggregation-file = "/etc/go-carbon/storage-aggregation.conf"
    # Worker threads count. Metrics sharded by "crc32(metricName) % workers"
    workers = 8
    # Limits the number of whisper update_many() calls per second. 0 - no limit
    max-updates-per-second = 0
    # Sparse file creation
    sparse-create = false
    enabled = true

    [cache]
    # Limit of in-memory stored points (not metrics)
    max-size = 10000000
    # Capacity of queue between receivers and cache
    # Strategy to persist metrics. Values: "max","sorted","noop"
    #   "max" - write metrics with most unwritten datapoints first
    #   "sorted" - sort by timestamp of first unwritten datapoint.
    #   "noop" - pick metrics to write in unspecified order,
    #            requires least CPU and improves cache responsiveness
    write-strategy = "max"

    [udp]
    listen = "0.0.0.0:2003"
    enabled = true
    # Enable optional logging of incomplete messages (chunked by max UDP packet size)
    log-incomplete = false
    # Optional internal queue between receiver and cache
    buffer-size = 0

    [tcp]
    listen = "0.0.0.0:2003"
    enabled = true
    # Optional internal queue between receiver and cache
    buffer-size = 0

    [pickle]
    listen = "0.0.0.0:2004"
    # Limit message size for prevent memory overflow
    max-message-size = 67108864
    enabled = true
    # Optional internal queue between receiver and cache
    buffer-size = 0

    [carbonlink]
    listen = "127.0.0.1:7002"
    enabled = true
    # Close inactive connections after "read-timeout"
    read-timeout = "30s"

    [carbonserver]
    # Please NOTE: carbonserver is not intended to fully replace graphite-web
    # It acts as a "REMOTE_STORAGE" for graphite-web or carbonzipper/carbonapi
    listen = "0.0.0.0:8080"
    # Carbonserver support is still experimental and may contain bugs
    # Or be incompatible with github.com/grobian/carbonserver
    enabled = true
    # Buckets to track response times
    buckets = 10
    # carbonserver-specific metrics will be sent as counters
    # For compatibility with grobian/carbonserver
    metrics-as-counters = false
    # Read and Write timeouts for HTTP server
    read-timeout = "60s"
    write-timeout = "60s"
    # Enable /render cache, it will cache the result for 1 minute
    query-cache-enabled = true
    # 0 for unlimited
    query-cache-size-mb = 0
    # Enable /metrics/find cache, it will cache the result for 5 minutes
    find-cache-enabled = true
    # Control trigram index
    #  This index is used to speed-up /find requests
    #  However, it will lead to increased memory consumption
    #  Estimated memory consumption is approx. 500 bytes per each metric on disk
    #  Another drawback is that it will recreate index every scan-frequency interval
    #  All new/deleted metrics will still be searchable until index is recreated
    trigram-index = true
    # carbonserver keeps track of all available whisper files
    # in memory. This determines how often it will check FS
    # for new or deleted metrics.
    scan-frequency = "5m0s"
    # Maximum amount of globs in a single metric in index
    # This value is used to speed-up /find requests with
    # a lot of globs, but will lead to increased memory consumption
    max-globs = 100
    # graphite-web-10-mode
    # Use Graphite-web 1.0 native structs for pickle response
    # This mode will break compatibility with graphite-web 0.9.x
    # If false, carbonserver won't send graphite-web 1.0 specific structs
    # That might degrade performance of the cluster
    # But will be compatible with both graphite-web 1.0 and 0.9.x
    graphite-web-10-strict-mode = true
    # Allows to keep track for "last time readed" between restarts, leave empty to disable
    internal-stats-dir = ""
    # Calculate /render request time percentiles for the bucket, '95' means calculate 95th Percentile. To disable this feature, leave the list blank
    stats-percentiles = [99, 98, 95, 75, 50]

    [receiver.http]
    protocol = "http"
    # This receiver receives data from POST requests body.
    # Data can be encoded in plain text format (default),
    # protobuf (with Content-Type: application/protobuf header) or
    # pickle (with Content-Type: application/python-pickle header).
    listen = ":2007"
    max-message-size = 67108864
    
    [receiver.kafka]
    protocol = "kafka"
    # Available options: "plain" (default), "protobuf", "pickle"
    parse-protocol = "plain"
    # Kafka connection parameters
    brokers = [ "kafka-hs:9092" ]
    topic = "graphite"
    partition = 0


    [dump]
    # Enable dump/restore function on USR2 signal
    enabled = false
    # Directory for store dump data. Should be writeable for carbon
    path = "/var/lib/graphite/dump/"
    # Restore speed. 0 - unlimited
    restore-per-second = 0

    [pprof]
    listen = "localhost:7007"
    enabled = false

    # Default logger
    [[logging]]
    logger = ""
    file = "stdout"
    level = "info"
    encoding = "mixed"
    encoding-time = "iso8601"
    encoding-duration = "seconds"

    [[logging]]
    logger = ""
    file = "stderr"
    level = "error"
    encoding = "mixed"
    encoding-time = "iso8601"
    encoding-duration = "seconds"
  storage-aggregation.conf: |
    # Aggregation methods for whisper files. Entries are scanned in order,
    # and first match wins. This file is scanned for changes every 60 seconds
    #
    #  [name]
    #  pattern = <regex>
    #  xFilesFactor = <float between 0 and 1>
    #  aggregationMethod = <average|sum|last|max|min>
    #
    #  name: Arbitrary unique name for the rule
    #  pattern: Regex pattern to match against the metric name
    #  xFilesFactor: Ratio of valid data points required for aggregation to the next retention to occur
    #  aggregationMethod: function to apply to data points for aggregation
    #
    [min]
    pattern = \.min$
    xFilesFactor = 0.1
    aggregationMethod = min

    [max]
    pattern = \.max$
    xFilesFactor = 0.1
    aggregationMethod = max

    [count]
    pattern = \.count$
    xFilesFactor = 0
    aggregationMethod = sum

    [lower]
    pattern = \.lower(_\d+)?$
    xFilesFactor = 0.1
    aggregationMethod = min

    [upper]
    pattern = \.upper(_\d+)?$
    xFilesFactor = 0.1
    aggregationMethod = max

    [sum]
    pattern = \.sum$
    xFilesFactor = 0
    aggregationMethod = sum

    [gauges]
    pattern = ^.*\.gauges\..*
    xFilesFactor = 0
    aggregationMethod = last

    [default_average]
    pattern = .*
    xFilesFactor = 0.5
    aggregationMethod = average
  storage-schemas.conf: |
    # Schema definitions for Whisper files. Entries are scanned in order,
    # and first match wins. This file is scanned for changes every 60 seconds.
    #
    #  [name]
    #  pattern = regex
    #  retentions = timePerPoint:timeToStore, timePerPoint:timeToStore, ...

    # Carbon's internal metrics. This entry should match what is specified in
    # CARBON_METRIC_PREFIX and CARBON_METRIC_INTERVAL settings
    [carbon]
    pattern = ^carbon\.
    retentions = 5s:1d,1m:90d

    [collectd]
    pattern = ^collectd.*
    retentions = 10s:1d,1m:28d,10m:1y

    [statsd]
    pattern = ^stats.*
    retentions = 10s:1d,1m:28d,10m:1y,1h:2y

    [screeps]
    pattern = ^screeps.*
    retentions = 15s:1d,1m:15d,5m:30d

    [default_1min_for_1day]
    pattern = .*
    retentions = 5s:1d,1m:28d